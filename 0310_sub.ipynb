{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the dummy variables created in a right way? True\n",
      "After creating dummy variables, the total number of features are:  (88619, 29)\n"
     ]
    }
   ],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# data visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "# Read in datamart\n",
    "df_datamart = pd.read_csv(f'./input/datamart/datamart_v8.csv', index_col=0)\n",
    "\n",
    "'''By checking the info of the df_datamart, the following vaiables are 'object' type and needs to be converted\n",
    "    to numeric when training data:\n",
    "        1. ID (Needs to be dropped when training)\n",
    "        2. ID_DayNum (Needs to be dropped)\n",
    "        3. Seed_a\n",
    "        4. Seed_b\n",
    "        5. Team_a_Loc\n",
    "        6. Team_b_Loc\n",
    "        7. Label (Label needs to be dropped)'''\n",
    "\n",
    "\n",
    "# --------------------------------------1. Data Preparing--------------------------------------------------------\n",
    "# Check missing\n",
    "def check_missing(df):\n",
    "    col_names = df.columns.to_series()\n",
    "    col_dtypes = df.dtypes\n",
    "    col_na_count = df.isnull().sum()\n",
    "    col_describe = df.describe().T\n",
    "    col_unique = df.nunique()\n",
    "\n",
    "    base_info = pd.concat([col_names, col_dtypes, col_na_count, col_unique],\n",
    "                          axis=1, keys=['col_names', 'col_dtypes',\n",
    "                                        'col_na_count', 'col_unique'], sort=False)\n",
    "    base_info = pd.concat([base_info, col_describe], axis=1, sort=False)\n",
    "\n",
    "    return base_info\n",
    "\n",
    "\n",
    "'''1. Review一下filter2是否filter正确'''\n",
    "\n",
    "\n",
    "def filter(df):\n",
    "    # 1. Filter out records without DayNum (i.e., DayNum == 999), which means there's no contest happened\n",
    "    filter1 = df[df['DayNum'] != 999]\n",
    "    # 2. Filter out the teams without seed, which means those teams never in tourney and useless\n",
    "    filter2 = filter1[~ ((filter1['Seed_a'].isnull()) | (filter1['Seed_b'].isnull()))]\n",
    "    return filter2\n",
    "\n",
    "\n",
    "# Check for distribution (for y or others)\n",
    "def check_distribution(df, check_list):\n",
    "    num_feature_list = df.dtypes[df.dtypes != 'object'].index\n",
    "    skew_score = df[num_feature_list].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    print('---------------------------')\n",
    "    print('skew score of numerical features:')\n",
    "    print('---------------------------')\n",
    "    skewness = pd.DataFrame({'skew_score': skew_score})\n",
    "    print(skewness)\n",
    "\n",
    "    for feature in check_list:\n",
    "        try:\n",
    "            sns.distplot(df[feature], fit=norm)\n",
    "            fig = plt.figure()\n",
    "            res = stats.probplot(df[feature], plot=plt)\n",
    "\n",
    "            print('---------------------------')\n",
    "            print('Skewness of \" %s \" is: %f' % (feature, df[feature].skew()))\n",
    "            print('Kurtosis of \" %s \" is: %f' % (feature, df[feature].kurt()))\n",
    "            print('---------------------------')\n",
    "        except ValueError:\n",
    "            print(str(feature) + 'ValueError')\n",
    "\n",
    "\n",
    "# Check for numeric variable correlations\n",
    "def check_correlations(df, check_type='num_feature', target='win'):\n",
    "    if check_type == 'num_feature':\n",
    "        check_list = df.dtypes[df.dtypes != 'object'].index\n",
    "        corrmat = df[check_list].corr()\n",
    "        plt.subplots(figsize=(12, 9))\n",
    "        sns.heatmap(corrmat, vmax=0.9, square=True)\n",
    "        plt.show()\n",
    "\n",
    "    elif check_type == 'target':\n",
    "        k = 10  # number of features for heatmap\n",
    "        corrmat = df.corr()\n",
    "        cols = corrmat.nlargest(k, target)[target].index\n",
    "        cm = np.corrcoef(df[cols].values.T)\n",
    "        sns.set(font_scale=1.25)\n",
    "        sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10},\n",
    "                    yticklabels=cols.values, xticklabels=cols.values)\n",
    "        plt.show()\n",
    "    return corrmat\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Check the missing condition of original datamart\n",
    "    datamart_check = check_missing(df_datamart)\n",
    "\n",
    "    # Filter out useless records and check missing condition\n",
    "#     filter = filter(df_datamart)\n",
    "    filter = df_datamart\n",
    "\n",
    "#     filter_check = check_missing(filter)\n",
    "\n",
    "    # Among the filtered records, check the proportion of regular and tourney counts\n",
    "    count_prep = filter.groupby('Label').count()\n",
    "\n",
    "    # Check if there's any duplicates based on ID_DayNum\n",
    "#     check_dup = filter[filter.duplicated('ID_DayNum', keep=False)]  # No duplicates found! Good!\n",
    "\n",
    "    # Check distribution of target: win,Score_diff\n",
    "    target_list = ['win']\n",
    "#     check_dist = check_distribution(filter, target_list)\n",
    "\n",
    "    # Check correlations among variable\n",
    "#     check_corr = check_correlations(filter)\n",
    "    # a.to_excel(r'E:\\DS_DA_prep\\Kaggle\\NCCA\\2020-NCAAM\\output\\corr_check2.xlsx')\n",
    "\n",
    "# ---------------------------------------2. Feature Engineering--------------------------------------\n",
    "'''1. Process:\n",
    "        a. Drop unnecessary variables: ID, ID_DayNum, TeamID_a, TeamID_b, DayNum(?),Seed_a,Seed_b;\n",
    "        b. Extract seed location (到底有没有意义？因为季前赛的seed是用季后赛填的）\n",
    "        c. Variables need to be one-hot: Team_a_Loc, Team_b_Loc,Label\n",
    "        d. Add one variable: Seed_Score_diff (Seed_Score_a - Seed_Score_b)\n",
    "'''\n",
    "'''Questions/Concerns:\n",
    "        a. Whether DayNum be used as a feature? If so, categorical or numeric?\n",
    "        b. Team_a_Loc and Team_b_Loc 基本就是反的，怎么处理？ - Done\n",
    "        c. Season 处理成Categorical 还是Numeric? - Numeric\n",
    "        d. Filter 出来的data只有03年以后的？？？？- Done\n",
    "'''\n",
    "# Reset the index of the final dataframe before starting feature engineering\n",
    "df_final = filter.reset_index().drop('index', axis=1)\n",
    "\n",
    "# Drop unecessary variables\n",
    "# drop_list = ['ID', 'ID_DayNum', 'TeamID_a', 'TeamID_b', 'DayNum', 'Seed_a', 'Seed_b'\n",
    "#              # 'Team_b_Loc'\n",
    "#              ]  # Whether DayNum will be used as a feature needs to be discussed\n",
    "drop_list = ['ID','ID_DayNum']\n",
    "ID = df_final[drop_list]  # Keep ID variables to refer back later\n",
    "df_final_drop = df_final.drop(drop_list, axis=1)\n",
    "\n",
    "\n",
    "# Change variable type\n",
    "# df_final_drop['Seed_Score_Diff'] = df_final_drop['Seed_score_a'] - df_final_drop['Seed_score_b']\n",
    "\n",
    "\n",
    "# One-hot: [Team_a_Loc,Label] and drop Team_a_Loc & Team_b_Loc\n",
    "def create_dummies(df):\n",
    "    all_dummy = pd.get_dummies(df)\n",
    "    # Check if all objects get into dummy variables\n",
    "    all_dummy_col = all_dummy.dtypes[all_dummy.dtypes == 'int64'].index.sort_values()\n",
    "    num_feature_list = df.dtypes[df.dtypes == 'int64'].index.sort_values()\n",
    "    test_var = (all_dummy_col == num_feature_list).all()\n",
    "    print('Does the dummy variables created in a right way?', test_var)\n",
    "    print('After creating dummy variables, the total number of features are: ', all_dummy.shape)\n",
    "    return all_dummy\n",
    "\n",
    "\n",
    "df_dummyall = create_dummies(df_final_drop)\n",
    "\n",
    "# ---------------------------------------------3. Model Selection-------------------------------------------\n",
    "# Machine learning library\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix, f1_score,log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "# import xgboost\n",
    "\n",
    "'''Model Tryout (Classification Problem):\n",
    "     1. Random Forest\n",
    "     2. XGBoost\n",
    "     3. AdaBoosting\n",
    "     4. GradientBoosting\n",
    "     5. Decision Tree\n",
    "     6. LogisticRegression\n",
    "'''\n",
    "# 3.1 Split target and features\n",
    "y = df_dummyall['win']\n",
    "X = df_dummyall.drop('win', axis=1)\n",
    "\n",
    "\n",
    "# 3.2 Initial step to test models - using CV (KFold) to conduct cross validation\n",
    "def LogLoss_score(y, ypred_prob):  # Evaluation metrics used by Kaggle\n",
    "    lossall = []\n",
    "    pair = zip(y, ypred_prob)\n",
    "    for value in pair:\n",
    "        loss = value[0] * np.log(value[1]) + (1 - value[0]) * np.log((1 - value[1]))\n",
    "        lossall.append(loss)\n",
    "    loss_score = -(1 / len(y)) * sum(lossall)\n",
    "    return loss_score\n",
    "\n",
    "\n",
    "def model_tryout(model, X, y, n_folds):\n",
    "    scores = np.zeros((10, 2))\n",
    "    i = 0\n",
    "#     models = make_pipeline(RobustScaler(), model)  # RobustScaler can be changed as StandardScaler\n",
    "    models = model\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)  # .get_n_splits(X)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[\n",
    "            test_index]\n",
    "        instance = models.fit(X_train.values, y_train)\n",
    "        ypred_test = instance.predict_proba(X_test)  # Using test dataset to predict\n",
    "        ypred_train = instance.predict_proba(X_train)  # Using train dataset to predict\n",
    "        \n",
    "#         return ypred_test, ypred_train\n",
    "        \n",
    "        scores[i, 0] = log_loss(y_test.values, ypred_test[:, 1])  # rmse for cv scores\n",
    "        scores[i, 1] = log_loss(y_train.values, ypred_train[:, 1])  # rmse for test\n",
    "        i = i + 1\n",
    "    model_select = pd.DataFrame(scores, columns=['Logloss_test', 'Logloss_train'])\n",
    "    return model_select\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X.fillna(0, inplace=True)\n",
    "    X= X[[    \n",
    "#  'ID',\n",
    " 'DayNum',\n",
    " 'Team_a_Loc_A',\n",
    " 'Team_a_Loc_H',\n",
    " 'Team_a_Loc_N',\n",
    "#  'FGM2_rate_diff',\n",
    "#  'FGM3_rate_diff',\n",
    "#  'FGM3_count_diff',\n",
    "#  'FTM_count_diff',\n",
    "#  'OR_diff',\n",
    "#  'DR_diff',\n",
    "#  'Ast_diff',\n",
    "#  'TO_diff',\n",
    "#  'Stl_diff',\n",
    "#  'Blk_diff',\n",
    "#  'PF_diff',\n",
    "#  'Score_diff',\n",
    "#  'Team_win_count_diff',\n",
    "#  'Team_lost_count_diff',\n",
    " 'win_rate_diff',\n",
    "#  'Team_win_score_sum_diff',\n",
    "#  'Team_lost_socre_sum_diff',\n",
    " 'Score_mean_diff',\n",
    " 'Seed_score_diff',\n",
    " 'Seed_five_year_avg_diff',\n",
    " 'Seed_five_count_avg_diff',\n",
    " 'Seed_total_count_avg_diff',\n",
    " 'Label_Reg',\n",
    "'Label_Tourney'\n",
    "#  'win',\n",
    "#  'ID_DayNum'\n",
    "         \n",
    "         ]]\n",
    "    tr = StandardScaler()\n",
    "    X_tr = pd.DataFrame(tr.fit_transform(X))\n",
    "    \n",
    "    #rf = model_tryout(RandomForestClassifier(verbose=False, random_state=1), X_tr, y, 10)\n",
    "    lr = model_tryout(LogisticRegression(), X_tr, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logloss_test</th>\n",
       "      <th>Logloss_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.463064</td>\n",
       "      <td>0.473073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.472727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470450</td>\n",
       "      <td>0.472249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459604</td>\n",
       "      <td>0.473452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.480849</td>\n",
       "      <td>0.471094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.482606</td>\n",
       "      <td>0.470894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.477775</td>\n",
       "      <td>0.471432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.478424</td>\n",
       "      <td>0.471359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.468673</td>\n",
       "      <td>0.472445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.474404</td>\n",
       "      <td>0.471811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Logloss_test  Logloss_train\n",
       "0      0.463064       0.473073\n",
       "1      0.466092       0.472727\n",
       "2      0.470450       0.472249\n",
       "3      0.459604       0.473452\n",
       "4      0.480849       0.471094\n",
       "5      0.482606       0.470894\n",
       "6      0.477775       0.471432\n",
       "7      0.478424       0.471359\n",
       "8      0.468673       0.472445\n",
       "9      0.474404       0.471811"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.303060</td>\n",
       "      <td>1.108838</td>\n",
       "      <td>-0.883236</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>1.598072</td>\n",
       "      <td>-0.463553</td>\n",
       "      <td>0.247336</td>\n",
       "      <td>0.123868</td>\n",
       "      <td>-0.672206</td>\n",
       "      <td>1.008661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160678</td>\n",
       "      <td>0.362682</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>-1.865624</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.006035</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>-0.112882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.970149</td>\n",
       "      <td>-0.901845</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>1.703930</td>\n",
       "      <td>0.469781</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>1.501290</td>\n",
       "      <td>-1.538190</td>\n",
       "      <td>-0.944200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158737</td>\n",
       "      <td>0.627654</td>\n",
       "      <td>-0.523485</td>\n",
       "      <td>-2.046942</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.006035</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>-0.112882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527947</td>\n",
       "      <td>1.108838</td>\n",
       "      <td>-0.883236</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>-0.596233</td>\n",
       "      <td>-2.507526</td>\n",
       "      <td>-0.753972</td>\n",
       "      <td>-1.253554</td>\n",
       "      <td>-1.884584</td>\n",
       "      <td>-3.176042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291605</td>\n",
       "      <td>-2.088302</td>\n",
       "      <td>-1.190971</td>\n",
       "      <td>-2.045238</td>\n",
       "      <td>-0.976385</td>\n",
       "      <td>-0.519711</td>\n",
       "      <td>-1.016110</td>\n",
       "      <td>-1.581389</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>-0.112882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.249253</td>\n",
       "      <td>-0.901845</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>-0.576809</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.497663</td>\n",
       "      <td>-0.171294</td>\n",
       "      <td>-0.152615</td>\n",
       "      <td>-1.223181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160678</td>\n",
       "      <td>-0.829688</td>\n",
       "      <td>-1.190971</td>\n",
       "      <td>-2.045238</td>\n",
       "      <td>-0.976385</td>\n",
       "      <td>-0.519711</td>\n",
       "      <td>-1.016110</td>\n",
       "      <td>-1.581389</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>-0.112882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084067</td>\n",
       "      <td>1.108838</td>\n",
       "      <td>-0.883236</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>-1.092908</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>1.248643</td>\n",
       "      <td>-1.056779</td>\n",
       "      <td>-0.152615</td>\n",
       "      <td>-1.362671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914629</td>\n",
       "      <td>-0.101017</td>\n",
       "      <td>-0.504844</td>\n",
       "      <td>-2.253371</td>\n",
       "      <td>-0.581220</td>\n",
       "      <td>-0.160138</td>\n",
       "      <td>-0.605804</td>\n",
       "      <td>-1.184495</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>-0.112882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.303060  1.108838 -0.883236 -0.357348  1.598072 -0.463553  0.247336   \n",
       "1 -0.970149 -0.901845  1.132200 -0.357348  1.703930  0.469781 -0.002991   \n",
       "2  0.527947  1.108838 -0.883236 -0.357348 -0.596233 -2.507526 -0.753972   \n",
       "3  1.249253 -0.901845  1.132200 -0.357348 -0.576809  0.006937  0.497663   \n",
       "4  0.084067  1.108838 -0.883236 -0.357348 -1.092908  0.006937  1.248643   \n",
       "\n",
       "         7         8         9   ...        14        15        16        17  \\\n",
       "0  0.123868 -0.672206  1.008661  ...  0.160678  0.362682  0.057269 -1.865624   \n",
       "1  1.501290 -1.538190 -0.944200  ... -1.158737  0.627654 -0.523485 -2.046942   \n",
       "2 -1.253554 -1.884584 -3.176042  ...  1.291605 -2.088302 -1.190971 -2.045238   \n",
       "3 -0.171294 -0.152615 -1.223181  ...  0.160678 -0.829688 -1.190971 -2.045238   \n",
       "4 -1.056779 -0.152615 -1.362671  ...  0.914629 -0.101017 -0.504844 -2.253371   \n",
       "\n",
       "         18        19        20        21        22        23  \n",
       "0  0.011529 -0.006035  0.009653  0.006187  0.112882 -0.112882  \n",
       "1  0.011529 -0.006035  0.009653  0.006187  0.112882 -0.112882  \n",
       "2 -0.976385 -0.519711 -1.016110 -1.581389  0.112882 -0.112882  \n",
       "3 -0.976385 -0.519711 -1.016110 -1.581389  0.112882 -0.112882  \n",
       "4 -0.581220 -0.160138 -0.605804 -1.184495  0.112882 -0.112882  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_DayNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2003_1102_1117</td>\n",
       "      <td>2003_1102_1117_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2003_1102_1125</td>\n",
       "      <td>2003_1102_1125_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2003_1102_1140</td>\n",
       "      <td>2003_1102_1140_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2003_1102_1140</td>\n",
       "      <td>2003_1102_1140_117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2003_1102_1161</td>\n",
       "      <td>2003_1102_1161_75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID           ID_DayNum\n",
       "0  2003_1102_1117   2003_1102_1117_25\n",
       "1  2003_1102_1125   2003_1102_1125_37\n",
       "2  2003_1102_1140   2003_1102_1140_91\n",
       "3  2003_1102_1140  2003_1102_1140_117\n",
       "4  2003_1102_1161   2003_1102_1161_75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
